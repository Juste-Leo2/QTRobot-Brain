# src/processing/function.py

import requests
import json
import time
import os
import yaml

# --- CONSTANTES (Format ChatML pour structurer le prompt) ---
BOS_TOKEN = "<|startoftext|>"
IM_START_TOKEN = "<|im_start|>"
IM_END_TOKEN = "<|im_end|>"

def load_config():
    """Charge la configuration depuis le fichier YAML."""
    try:
        config_path = os.path.join(os.path.dirname(__file__), '..', '..', 'config', 'config.yaml')
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    except Exception:
        return None

def build_tool_prompt(user_query: str, tools: list = None) -> str:
    """
    Construit un prompt tr√®s directif avec des exemples (Few-Shot) 
    pour forcer le choix entre get_vision, get_time ou None.
    
    Note: L'argument 'tools' est gard√© pour la compatibilit√© de signature, 
    mais les outils sont maintenant hardcod√©s dans le prompt comme demand√©.
    """
    
    # D√©finition stricte des outils et des exemples pour guider le LLM
    system_message = (
        "You are a precise tool selector. Your ONLY job is to return the correct tool name based on the user's request.\n"
        "AVAILABLE TOOLS:\n"
        "- get_vision: Use ONLY if the user asks to describe, see, look at, or analyze an image or photo.\n"
        "- get_time: Use ONLY if the user asks for the current time, date, or hour.\n"
        "- None: Use if the request is conversational (hello, how are you) or doesn't match the tools above.\n\n"
        "EXAMPLES:\n"
        "User: What time is it?\nTool: get_time\n"
        "User: Can you describe this picture?\nTool: get_vision\n"
        "User: Hello assistant.\nTool: None\n"
        "User: What do you see?\nTool: get_vision\n"
        "User: Give me the date.\nTool: get_time"
    )

    # Construction du prompt avec les balises
    prompt = f"{BOS_TOKEN}{IM_START_TOKEN}system\n{system_message}{IM_END_TOKEN}\n"
    
    # La requ√™te actuelle de l'utilisateur
    prompt += f"{IM_START_TOKEN}user\n{user_query}{IM_END_TOKEN}\n"
    
    # Force le d√©but de la r√©ponse pour que le LLM ne compl√®te que le mot manquant
    prompt += f"{IM_START_TOKEN}assistant\nTool:"
    
    return prompt

def choose_tool(user_query: str, server_url: str, headers: dict) -> str:
    """
    Interroge le LLM pour choisir l'outil appropri√©.
    Entr√©es et sorties conserv√©es pour la portabilit√©.
    """
    # On appelle le constructeur de prompt (tools est ignor√© dedans)
    prompt = build_tool_prompt(user_query)
    
    payload = {
        "prompt": prompt,
        "temperature": 0.0,      # Z√©ro cr√©ativit√© requise pour du routage
        "n_predict": 10,         # On attend juste un mot
        "stop": [IM_END_TOKEN, "\n", "User:"] # Arr√™ts stricts
    }

    # --- Gestion du Retry (identique √† chat.py) ---
    max_retries = 30
    
    for attempt in range(max_retries):
        try:
            # Utilisation de json=payload pour la coh√©rence
            response = requests.post(server_url, headers=headers, json=payload)
            
            if response.status_code == 503:
                # Mod√®le en chargement
                time.sleep(2)
                continue

            response.raise_for_status()

            response_data = response.json()
            
            # Nettoyage de la r√©ponse
            content = response_data['content'].strip()
            
            # S√©curit√© : si le LLM r√©p√®te "Tool: get_time", on nettoie
            if content.startswith("Tool:"):
                content = content.replace("Tool:", "").strip()
            
            # S√©curit√© : on s'assure que c'est un des mots cl√©s attendus, sinon None
            valid_tools = ["get_vision", "get_time", "None"]
            # On peut √™tre tol√©rant sur la casse ou les espaces
            for tool in valid_tools:
                if tool.lower() in content.lower():
                    return tool
            
            # Si le LLM a r√©pondu quelque chose d'inattendu (ex: "I don't know"), on renvoie None par s√©curit√©
            return "None"
            
        except requests.exceptions.ConnectionError:
            time.sleep(2)
            continue
        except Exception as e:
            # En cas d'erreur critique, on renvoie None ou on raise (selon pr√©f√©rence)
            # Ici on raise pour le debug comme demand√©
            raise e

    raise requests.exceptions.HTTPError("Timeout: Serveur injoignable.")

def main_function_loop():
    """Boucle principale pour tester la s√©lection de fonction en console."""
    
    config = load_config()
    
    if config and 'llm_server' in config:
        SERVER_URL = config['llm_server']['url']
        HEADERS = config['llm_server']['headers']
    else:
        # Fallback
        SERVER_URL = "http://localhost:8084/completion"
        HEADERS = {"Content-Type": "application/json"}
    
    print("Assistant de s√©lection (get_vision / get_time / None).")
    print(f"Connect√© √† : {SERVER_URL}")
    print("Tapez 'exit' pour quitter.")
    print("-" * 30)

    while True:
        try:
            user_input = input("Votre question : ")
            if user_input.lower() in ["exit", "quit"]:
                break
            
            chosen_function = choose_tool(user_input, SERVER_URL, HEADERS)
            
            # Affichage visuel pour confirmer le bon choix
            if chosen_function == "get_vision":
                print(f"-> üëÅÔ∏è  Outil choisi : {chosen_function}")
            elif chosen_function == "get_time":
                print(f"-> ‚è∞ Outil choisi : {chosen_function}")
            else:
                print(f"-> ‚ùå Outil choisi : {chosen_function}")
            print("")

        except requests.exceptions.RequestException as e:
            print(f"Erreur connexion : {e}")
            break
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"Erreur : {e}")

if __name__ == "__main__":
    main_function_loop()