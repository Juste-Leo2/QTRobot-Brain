#!/bin/bash

# Arr√™t imm√©diat en cas d'erreur
set -e

# LA VERSION CIBLE (Celle que tu m'as donn√©e)
TARGET_VERSION="b6987"

echo "üöÄ COMPILATION CIBL√âE LLAMA.CPP (Version : $TARGET_VERSION)"
echo "------------------------------------------------------------"

# 1. V√©rification des outils
echo "üì¶ V√©rification des d√©pendances..."
sudo apt-get update
sudo apt-get install -y build-essential cmake git curl libcurl4-openssl-dev

# 2. Dossier de travail
TARGET_DIR="models/llama_cpp"
mkdir -p "$TARGET_DIR"
cd "$TARGET_DIR"

# 3. Gestion des sources GIT
if [ -d "llama.cpp_source" ]; then
    echo "üîÑ Dossier source existant trouv√©."
    cd llama.cpp_source
    
    # On nettoie les modifs locales pour √©viter les conflits
    echo "   Reset des modifications locales..."
    git reset --hard
    
    # On r√©cup√®re tout l'historique pour trouver la version
    echo "   T√©l√©chargement de l'historique git..."
    git fetch --all --tags
else
    echo "üì• Clonage complet du d√©p√¥t..."
    git clone https://github.com/ggml-org/llama.cpp llama.cpp_source
    cd llama.cpp_source
fi

# 4. PASSAGE A LA VERSION SPECIFIQUE
echo "üîô ROLLBACK vers la version : $TARGET_VERSION"
# Checkout permet de revenir dans le pass√© √† ce commit pr√©cis
git checkout "$TARGET_VERSION"

# 5. Mise √† jour des sous-modules pour CETTE version sp√©cifique
echo "üì¶ Mise √† jour des sous-modules..."
git submodule update --init --recursive

# 6. Nettoyage du build
echo "üßπ Pr√©paration du dossier build..."
rm -rf build
mkdir build
cd build

# 7. Configuration CMake
# Note : Sur les vieilles versions, DLLAMA_CURL n'existait peut-√™tre pas encore.
# On garde les flags standards optimis√©s pour ton i5.
echo "‚öôÔ∏è  Configuration CMake..."
cmake .. \
    -DGGML_NATIVE=ON \
    -DBUILD_SHARED_LIBS=OFF \
    -DLLAMA_BUILD_SERVER=ON \
    -DLLAMA_CURL=ON \
    -DCMAKE_BUILD_TYPE=Release

# 8. Compilation
echo "üî® Compilation en cours (Version $TARGET_VERSION)..."
cmake --build . --config Release -j $(nproc)

# 9. Installation
echo "üöö Copie des ex√©cutables..."

# Gestion des noms (server vs llama-server selon l'√©poque)
if [ -f "bin/llama-server" ]; then
    NEW_BIN="bin/llama-server"
elif [ -f "bin/server" ]; then
    NEW_BIN="bin/server"
else
    echo "‚ùå ERREUR : Binaire introuvable dans bin/. V√©rifie les logs de compilation."
    exit 1
fi

# Retour au dossier models/llama_cpp
cd ../..

# Copie et droits
cp "llama.cpp_source/build/$NEW_BIN" ./llama-server
chmod +x ./llama-server
echo "   ‚úÖ llama-server restaur√© en version $TARGET_VERSION."

# Copie pour la vision
cp ./llama-server ./llama-server-vision
echo "   ‚úÖ llama-server-vision restaur√©."

echo "------------------------------------------------------------"
echo "üéâ SUCC√àS ! Tu es maintenant sur la version $TARGET_VERSION."
echo "   Tu peux relancer : python3 main.py --QT"